\documentclass{article}

\usepackage{amsmath}
\usepackage{parskip}
\usepackage{tikz}
\renewcommand{\emph}{\textbf}
\renewcommand{\bar}{\overline}
\DeclareMathOperator{\Log}{Log}
\DeclareMathOperator{\Arg}{Arg}
\DeclareMathOperator{\sech}{sech}
\DeclareMathOperator{\csch}{csch}

\begin{document}

\section{Frame 55 -- Sequences and Convergence}
\subsection{Definitions}
An \emph{infinite sequence} of complex numbers,
\[
	z_1, z_2, \dots, z_n, \dots
\]
has a \emph{limit} if, for each positive number $\epsilon$, there exists a positive integer $n_0$ such that
\[
	|z_n - z| < \epsilon	\quad \text{whenever} \quad	n > n_0
\]
Geometrically, this limit implies that for all $n > n_0$, each number $z_n$ in the sequence will be inside an $\epsilon$ neighbourhood of $z$.

A sequence can only have one limit, at most. When this limit exists, we say that the sequence \emph{converges} to $z$, and we write
\[
	\lim_{n \to \infty} z_n = z
\]
If a sequence has no limit, it \emph{diverges}.

\subsection{Components}
\textit{Theorem: If we write $z_n = x_n + iy_n$ and $z = x + iy$, then
\[
	\lim_{n \to \infty} z_n = z \iff
	\lim_{n \to \infty} x_n = x \text{ and }
	\lim_{n \to \infty} y_n = y
\]}
This theorem allows us to write
\[
	\lim_{n \to \infty} (x_n + iy_n)
	= \lim_{n \to \infty} x_n 
	+ i \lim_{n \to \infty} y_n
\]
as long as the limits on either side of this equation exist.

\subsection{Examples}
\textit{Example 1: we can evaluate the following limit easily:
\begin{align*}
	\lim_{n \to \infty} \frac{1}{n^3 + i}
	&= \lim_{n \to \infty} \frac{1}{n^3} + i\lim_{n \to \infty} 1 \\
	&= 0 + i\cdot1 \\
	&= i
\end{align*}
}

\textit{Example 2: Polar coordinates require some extra care. Looking at the sequence
\[
	z_n = -2 + i \frac{(-1)^n}{n^2}
\]
we can see that
\[
	\lim_{n \to \infty} z_n
	= \lim_{n \to \infty} (-2)
	+ i \lim_{n \to \infty} \frac{(-1)^n}{n^2}
	= -2
\]
However, we can find that the principal polar representation of these numbers is
\begin{align*}
	r_n &= \sqrt{4 + \frac{1}{n^2}} \\
	\Theta_n &= \Arg z_n = \tan^{-1} \left( \frac{(-1)^n}{-2n^2}\right)
\end{align*}
Evaluating the first limit, we find that
\[
	\lim_{n \to \infty} r_n = \sqrt{4} = 2
\]
which is fine. However, the second sequence does not converge. Looking at every second term, we see that
\[
	\lim_{n \to \infty} \Theta_{2n} = \pi
\]
and
\[
	\lim_{n \to \infty} \Theta_{2n - 1} = -\pi
\]
so $\Theta_n$ diverges.}


\clearpage
\section{Frame 56 -- Series Convergence}
\subsection{Definitions}
An infinite \emph{series} of complex numbers,
\[
	\sum_{n=1}^\infty z_n = z_1 + z_2 + z_3 + \dots + z_n + \dots,
\]
\emph{converges} to the sum $S$ if the sequence of partial sums,
\[
	S_N = \sum_{n=1}^N z_n = z_1 + z_2 + \dots + z_N,
\]
converges to $S$. If this is the case, then we can write
\[
	\sum_{n=1}^\infty z_n = S
\]

Note that, since a sequence can have at most one limit, a series can have at most one sum. If a series does not converge, it \emph{diverges}.

\subsection{Properties -- Components}
First, as with sequences, we can split a series into its real and imaginary components.

\textit{Theorem: If $z_n = x_n + iy_n$ and $S = X + iY$, then
\[
	\sum_{n=1}^\infty z_n = S
\]
iff
\[
	\sum_{n=1}^\infty x_n = X \quad \text{and} \quad \sum_{n=1}^\infty y_n = Y
\]}

To prove this, we can write the partial sums $S_N$ as
\[
	S_N = X_N + iY_N
\]
where
\[
	X_N = \sum_{n=1}^N x_n \quad \text{and} \quad Y_N = \sum_{n=1}^N y_ns
\]
Then, the series only converges to $S$ if
\[
	\lim_{N \to \infty} X_N = X \quad \text{and} \quad \lim_{N \to \infty} Y_N = Y
\]
due to the theorem on sequences in the previous chapter. Thus, the theorem is proved.

\subsection{Properties -- Boundedness}
The following corollary is a consequence of the previous theorem: 

\textit{Corollary 1: If a series of complex numbers converges, the summed terms $z_n$ converge to zero.}

This is due to the fact that
\[
	\sum_{n=1}^\infty z_n = \sum_{n=1}^\infty x_n + i \sum_{n=1}^\infty y_n
\]
and, in order for these two terms to converge, $x_n$ and $y_n$ must converge to zero (from calculus). Thus,
\[
	\lim_{n \to \infty} z_n 
	= \lim_{n \to \infty} x_n + i \lim_{n \to \infty} y_n
	= 0
\]

This corollary implies that the terms within convergent series are bounded -- that is, there exists a constant $M$ such that $|z_n| < M$ for all $n$.

\subsection{Properties -- Absolute Convergence}
A series is \emph{absolutely convergent} if the related series
\[
	\sum_{n=1}^\infty |z_n| = \sum_{n=1}^\infty \sqrt{x_n^2 + y_n^2}
\]
converges. This has a simple implication:

\textit{Corollary 2: If a series is absolutely convergent, it is convergent.}

To show this, consider the real component of the series. It can be written as
\[
	\sum_{n=1}^\infty x_n
	\le \left| \sum_{n=1}^\infty x_n \right|
	\le \sum_{n=1}^\infty |x_n|
	\le \sum_{n=1}^\infty \sqrt{x_n^2 + y_n^2}
	= 0
\]
so the real component must converge. The same is true of the imaginary component, so the corollary is proved.

\subsection{Remainders}
It is often helpful to define the sequence of \emph{remainders} using the partial sums:
\[
	\rho_N = S - S_N
\]
or $S = S_N + \rho_N$. Since we can write that
\[
	|S_N - S| = |\rho_N|
\]
then a series is only convergent if the sequence of remainders tends to zero.

\textit{Example: using remainders, we can verify that
\[
	\sum_{n=0}^\infty z_n = \frac{1}{1 - z} \quad \text{whenver} \quad |z| < 1
\]
To do this, we recall that
\[
	S_N(z) = 1 + z + z^2 + \dots + z^N = \frac{1 - z^{N+1}}{1 - z}
\]
so
\[
	\rho_N(z) = \frac{1}{1 - z} - \frac{1 - z^{N+1}}{1 - z}
	= \frac{z^N}{1 - z}
\]
The moduli of these remaiders are
\[
	|\rho_N(z)| = \frac{|z|^N}{|1 - z|}
\]
so $\rho_N(z)$ tends to zero when $|z| < 1$.}


\clearpage
\section{Frame 57 -- Taylor Series}
The following theorem is known as \emph{Taylor's theorem}:

\textit{Theorem: If a function $f$ is analytic throughout a disk $|z - z_0| < R_0$, then $f(z)$ has the power series representation
\[
	f(z) = \sum_{n = 0}^\infty a_n (z - z_0)^n
\]
where
\[
	a_n = \frac{f^{(n)} (z_0)}{n!}
\]
This series converges to $f(z)$ when $z$ is in this disk.}

Taylor's theorem allows us to write
\[
	f(z) = f(z_0) 
	+ \frac{f'(z_0)}{1!}  (z - z_0)
	+ \frac{f''(z_0)}{2!} (z - z_0)^2
	+ \dots 
\]
This is true for any function that is analytic at $z_0$: the requirement for analyticity states that $f$ must be analytic in some neighbourhood of $z_0$, so the disk mentioned in the theorem exists. In particular, entire functions can use arbitrarily large disks, ie:
\[
	|z - z_0| < \infty
\]
so the series is convergent for all $z$ in the plane.

It can be shown that Taylor's series converges at every point inside the disk -- no convergence tests are required. In fact, the smallest radius at which it does \emph{not} converge is the nearest point where $f$ is not analytic. 

If $z_0 = 0$ in a Taylor series, it is known as a \emph{Maclaurin series}. Then, it takes the form
\[
	f(z) = \sum_{n=0}^\infty \frac{f^{(n)}(0)}{n!} z^n
\]


\clearpage
\section{Frame 59 -- Examples of Taylor Series}
In this section, we will use the formula
\[
	a_n = \frac{f^{(n)}(z_0)}{n!}
\]
to find the Maclaurin expansions of some common functions.

\subsection{Example 1}
The function $e^x$ is entire, so its Maclaurin expansion is valid for all $z$. Since
\[
	f^{(n)}(z) = e^z
\]
each term is $a_n = 1/n!$, so we find that
\[
	e^z = \sum_{n=0}^\infty \frac{z^n}{n!}
\]
Note that, if $z = x + i0$, then
\[
	e^x = \sum_{n=0}^\infty \frac{x^n}{n!}
\]
as expected.

We can use this result to find the Maclaurin series for the entire function $z^2 e^{3z}$. By replacing $z$ with $3z$ and multiplying through by $z^2$, we find
\[
	z^2 e^{3z} = \sum_{n=0}^\infty \frac{3^n}{n!} z^{n+2} 
	= \sum_{n=2}^\infty \frac{3^{n-2}}{(n-2)!} z^n
\]

\subsection{Example 2}
Using the expansion
\[
	\sin z = \frac{1}{2i} (e^{iz} - e^{-iz})
\]
we can find the Maclaurin series for $f(z) = \sin z$. To do this, we write
\begin{align*}
	\sin z 
	&= \frac{1}{2i} \left[ \sum_{n=0}^\infty \frac{(iz)^n}{n!} - \sum_{n=0}^\infty \frac{(-iz)^n}{n!}  \right] \\
	&= \frac{1}{2i} \sum_{n=0}^\infty [1 - (-1)^n] \frac{i^n}{n!} z^n \\
\intertext{Then, $1 - (-1)^n$ is zero for $n$ even, so only taking odd terms gives}
	&= \frac{1}{2i} \sum_{n=0}^\infty 2 \frac{i^{2n+1}}{(2n+1)!} z^{2n+1} \\
	&= \sum_{n=0}^\infty \frac{(-1)^n}{(2n + 1)!} z^{2n + 1}
\end{align*}

This expansion can be used directly to find $\cos z$. Since
\[
	\cos z = \frac{d}{dz} \sin z
\]
we can write
\begin{align*}
	\cos z
	&= \sum_{n=0}^\infty \frac{(-1)^n}{(2n + 1)!} \frac{d}{dz} z^{2n + 1} \\
	&= \sum_{n=0}^\infty \frac{(-1)^n}{(2n + 1)!} (2n + 1) z^{2n} \\
	&= \sum_{n=0}^\infty \frac{(-1)^n}{(2n)!} z^{2n}
\end{align*}

\subsection{Example 3}
Since
\[
	\sinh z = -i\sin(iz)
\]
we can write
\begin{align*}
	\sinh z &= -i \sum_{n=0}^\infty \frac{(-1)^n}{(2n + 1)!} (iz)^{2n + 1} \\
	&= \sum_{n=0}^\infty \frac{(-1)^n}{(2n + 1)!} (-1)^n z^{2n+1} \\
	&= \sum_{n=0}^\infty \frac{1}{(2n + 1)!} z^{2n+1} \\
\end{align*}
Similarly,
\[
	\cosh z
	= \sum_{n=0}^\infty \frac{1}{(2n)!} z^{2n}
\]
Also, note that $\cosh z = \cosh (z + 2\pi i)$, so
\[
	\cosh z = \sum_{n=0}^\infty \frac{1}{(2n)!} (z + 2\pi i)^{2n}
\]

\subsection{Example 4}
If $f(z) = \frac{1}{1 - z}$, then
\[
	f^{(n)}(z) = \frac{n!}{(1 - z)^{n+1}}
\]
so
\[
	\frac{1}{1 - z} = \sum_{n=0}^\infty z^n
\]

If we substitute $-z$ for this expression, we find that
\[
	\frac{1}{1 + z} = \sum_{n=0}^\infty (-1)^n z^n
\]
and if we substitute $1 - z$ instead, we find
\[
	\frac{1}{z} = \sum_{n=0}^\infty (-1)^n (z - 1)^n
\]

Note that all three of these Taylor series have a radius of convergence of $1$.

\subsection{Example 5}
Notice that the function
\[
	f(z) \frac{1}{z^3} \frac{1}{1 + z^2}
\]
does not have a Maclaurin series -- it is not analytic at $z = 0$. However,
\[
	\frac{1}{1 + z^2} = 1 - z^2 + z^4 - z^6 + \dots
\]
so we can write
\begin{align*}
	f(z) 
	&= \frac{1}{z^3} (1 - z^2 + z^4 - z^6 + \dots) \\
	&= z^{-3} - z^{-1} + z^1 - z^3 + \dots
\end{align*}
We refer to the first two terms as \emph{negative powers} of $z$.


\clearpage
\section{Frame 60 -- Laurent Series}
\subsection{Definition}
We saw in the previous section that we often able to find series representations of functions that are not analytic by using both positive and negative powers of $z$. These representations are known as \emph{Laurent series}. The central theorem for these functions is Laurent's theorem:

\textit{Theorem: Suppose that a function $f$ is analytic over an annular domain,
\[
	R_1 < |z - z_0| < R_2
\]
Then, $f(z)$ has the series representation
\[
	f(z) 
	= \sum_{n=0}^\infty a_n (z - z_0)^n
	+ \sum_{n=0}^\infty \frac{b_n}{(z - z_0)^n}
\]
where
\begin{align*}
	a_n &= \frac{1}{2\pi i} \int_C \frac{f(z)}{(z - z_0)^{ n+1}} dz \\
	b_n &= \frac{1}{2\pi i} \int_C \frac{f(z)}{(z - z_0)^{-n+1}} dz
\end{align*}
and where $C$ is any positively-oriented contour in this domain containing $z_0$.}

\subsection{Alternate Form}
Note that we can write this series more simply by defining
\[
	c_n = 
	\begin{cases}
		b_{-n},	& n < 0 \\
		a_n,	& n \ge 0
	\end{cases}
\]
and writing
\[
	f(z) = \sum_{n=-\infty}^\infty c_n (z - z_0)^n
\]
Looking at the expressions for $a_n$ and $b_n$,
\[
	c_n = \frac{1}{2\pi i} \int_C \frac{f(z)}{(z - z_0)^{n+1}} dz
\]

\subsection{Observations}
First, note that
\[
	b_n = \frac{1}{2\pi i} \int_C f(z) (z - z_0)^{n-1} dz
\]
If $f(z)$ is analytic wherever $|z - z_0| < R_2$, then all of these coefficients will be zero, and the Laurent series reduces to a Taylor series. 

The domain of definition could expand to several different possibilities:
\begin{itemize}
	\item $|z - z_0| < R_2$, if $f$ is analytic everywhere inside this disk (note that this is now a Taylor series)
	
	\item $0 < |z - z_0| < R_2$, if $f$ is analytic everywhere except for $z_0$ inside the $R_2$ disk
	
	\item $R_1 < |z - z_0| < \infty$, if $f$ is analytic everywhere outside the $R_1$ disk
	
	\item $0 < |z - z_0| < \infty$, if $f$ is analytic everywhere in the plane except for $z_0$
\end{itemize}


\clearpage
\section{Frame 62 -- Examples of Laurent Series}
This section will show some examples of Laurent series.

\subsection{Example 1}
First, using the expansion for $e^z$, the Laurent series for $e^{1/z}$ is
\[
	e^{1/z} = \sum_{n=0}^\infty \frac{1}{n! z^n}
	= 1 + \frac{1}{z} + \frac{1}{2z^2} + \frac{1}{6z^3} + \dots
\]
Note that the coefficient $b_1$ here is $1$, which tells us that
\[
	\int_C e^{1/z} dz = 2\pi i
\]
for any positively-oriented simple closed contour that contains the origin.

\subsection{Example 2}
The function
\[
	\frac{1}{(z - i)^2}
\]
is already a Laurent series, where $c_n = 0$ for all $n$ except $c_{-2} = 1$. This tells us that
\[
	\int_C \frac{dz}{(z - i)^{n+3}} = \begin{cases}
		0,		& n \ne -2 \\
		2\pi i, & n   = -2
	\end{cases}
\]

\subsection{Example 3}
Consider the function
\[
	f(z) = \frac{1}{z - 1} - \frac{1}{z - 2}
\]
in the domain $|z| < 1$. Since $f$ is analytic in this domain, we can write the Maclaurin series
\begin{align*}
	f(z) 
	&= \frac{-1}{1 - z} + \frac{1}{2} \frac{1}{1 - z/2} \\
	&= -\sum_{n=0}^\infty z^n + \sum_{n=0}^\infty \frac{z^n}{2^{n+1}} \\
	&= \sum_{n=0}^\infty (2^{-n-1} - 1) z^n 
\end{align*}

\subsection{Example 4}
Consider the same function on the domain $1 < |z| < 2$. Here, we can write
\[
	|1/z| < 1 \quad \text{and} \quad |z/2| < 1
\]
so we can write the function as
\begin{align*}
	f(z)
	&= \frac{1}{z} \frac{1}{1 - 1/z} + \frac{1}{2} \frac{1}{1 - z/2} \\
	&= \sum_{n=0}^\infty \frac{1}{z^{n+1}} + \sum_{n=0}^\infty \frac{z^n}{2^{n+1}} \\
	&= \sum_{n=0}^\infty \frac{z^n}{2^{n+1}} + \sum_{n=1}^\infty \frac{1}{z^n}
\end{align*}
which is the Laurent series for $f$ in this domain.

\subsection{Example 5}
Finally, consider this function on the domain $2 < |z| < \infty$. Now, we can write
\begin{align*}
	f(z)
	&= \frac{1}{z} \frac{1}{1 - 1/z} - \frac{1}{z} \frac{1}{1 - 2/z} \\
	&= \sum_{n=0}^\infty \frac{1}{z^{n+1}} - \sum_{n=0}^\infty \frac{2^n}{z^{n+1}} \\
	&= \sum_{n=0}^\infty \frac{1 - 2^n}{z^{n+1}} \\
	&= \sum_{n=1}^\infty \frac{1 - 2^{n-1}}{z^n}
\end{align*}
which is the Laurent series for $f$ in this domain. Note that $a_n = 0$ for all $n$.


\clearpage
\section{Frame 63 -- Absolute \& Uniform Convergence}
This section will discuss several properties of power series.

\subsection{Absolute Convergence}
The first theorem will discuss when a power series is convergent.

\textit{Theorem: if a power series
\[
	\sum_{n=0}^\infty a_n(z - z_0)^n
\]
converges at the point $z = z_1 \neq z_0$, then it is absolutely convergent on the open disk $|z - z_0| < |z_1 - z_0|$.}

Proof: since the series converges, all of its terms must be bounded, so we can write
\[
	|a_n (z_1 - z_0)^n| \le M
\]
for some positive $M$. Then, for each $z$ inside the open disk described above, we can write
\[
	|a_n (z - z_0)^n | = |a_n (z - z_1)^n | \left(\frac{|z - z_0|}{|z_1 - z_0|}\right)^n \le M\rho^n
\]
where $\rho$ must be less than one. Then, the series must be less than the convergent geometric series
\[
	\sum_{n=0}^\infty M\rho^n
\]
so the power series is absolutely convergent on this open disk.

\textit{Note: we refer to the circle $|z - z_0| = |z_1 - z_0|$ as the \emph{circle of convergence} -- it is the largest circle around $z_0$ such that the power series converges everywhere inside it.}

\subsection{Uniform Convergence}
Next, we will define uniform convergence. We said earlier that the remainder of a series is the infinite sum less the partial sum
\[
	\rho_N(z) = S(z) - S_N(z)
\]
and that, in order to converge, these remainders must approach zero as $N$ approaches infinity. We can write this as
\[
	|\rho_N(z)| < \epsilon \quad \text{whenever} \quad N > N_\epsilon
\]
We say that a series is \emph{uniformly convergent} in a region if our choice of $N_\epsilon$ depends only on $\epsilon$ and not on $z$.

\textit{Theorem: If $z_1$ is a point inside the circle of convergence of a power series
\[
	\sum_{n=0}^\infty a_n (z - z_0)^n
\]
then that series must be uniformly convergent in the closed disk $|z - z_0| \le |z_1 - z_0|$.}


\clearpage
\section{Frame 64 -- Continuity of Power Series}
\subsection{Continuity}
The following theorem is a consequence of uniform convergence.

\textit{Theorem: A power series
\[
	\sum_{n=0}^\infty a_n (z - z_0)^n
\]
represents a continuous function $S(z)$ at each point inside its circle of convergence.}

To show this, we can write $S(z)$ as a partial sum plus the remainder:
\[
	S(z) = S_N(z) + \rho_N(z)
\]
Then, we wish to show that
\[
	|S(z) - S(z_1)| < \epsilon \quad \text{whenever} \quad |z - z_1| < \delta
\]
but
\begin{align*}
	|S(z) - S(z_1)| 
	&= |S_N(z) + \rho_N(z) - S_N(z_1) - \rho_N(z_1)| \\
	&\le |S_N(z) - S_N(z_1)| + |\rho_N(z)| + |\rho_N(z_1)|
\end{align*}
Now, the first term is a difference of two polynomials, which are continuous, so we must be able to choose a $\delta$ small enough to satisfy
\[
	|S_N(z) - S_N(z_1)| < \frac{\epsilon}{3} \quad \text{whenever} \quad |z - z_1| < \delta
\]
Then, due to uniform convergence, there exists an $N_\epsilon$ such that
\[
	|\rho_N(z)| < \frac{\epsilon}{3} \quad \text{whenever} \quad N > N_\epsilon
\]
which takes care of the latter two terms. Thus, for all $N > N_\epsilon$,
\[
	|S(z) - S(z_1)| < 3 \cdot \frac{\epsilon}{3} \quad \text{whenever} \quad
	|z - z_1| < \delta
\]
so $S(z)$ is continuous.

\subsection{Adjustments for Laurent series}
For series of the form
\[
	\sum_{n=1}^\infty \frac{b_n}{(z - z_0)^n}
\]
we can write the complex number
\[
	w = \frac{1}{z - z_0}
\]
to turn the series into the form
\[
	\sum_{n=1}^\infty b_n w^n
\]
which converges absolutely to a continuous function whenever $|w| < \frac{1}{|z_1 - z_0|}$. This implies that the function converges on the \emph{outside} of the circle
\[
	|z - z_0| > |z_1 - z_0|
\]
rather than the inside.


\clearpage
\section{Frame 65 -- Integration and Differentiation}
\subsection{Integration}
Next, we will look at integration of the power series
\[
	S(z) = \sum_{n=0}^\infty a_n(z - z_0)^n
\]
which represents a continuous function on its circle of convergence.

\textit{Theorem: Suppose that $C$ is a contour that is inside the circle of convergence of this power series, and let $g(z)$ be any function that is continuous on $C$. Then,
\[
	\int_C g(z) S(z) dz = \sum_{n=0}^\infty a_n \int_C g(z) (z - z_0)^n
\]}

Since both $g(z)$ and $S(z)$ are continuous on $C$, their product can be written as
\[
	g(z) S(z) = \sum_{n=0}^{N-1} a_n g(z) (z - z_0)^n + g(z) \rho_N(z)
\]
so the integral can be written as
\[
	int_C g(z) S(z) dz = \sum_{n=0}^{N-1} a_n \int_C g(z) (z - z_0)^n dz
	+ \int_C g(z) \rho_N(z) dz
\]
Then, uniform convergence tells us that there exists an integer $N_\epsilon$ such that
\[
	|\rho_N(z)| < \epsilon \quad \text{whenever} \quad N > N_\epsilon
\]
so
\[
	\left| \int_C g(z) \rho_N(z) dz \right| < M\epsilon L \quad \text{whenever} \quad N > N_\epsilon
\]
which implies that this integral vanishes as $N$ approaches infinity, and the theorem is proved.

\subsection{Analyticity}
Using the previous theorem, consider the special case $g(z) = 1$. Then, each of the integrals evaluate to
\[
	\int_C g(z) (z - z_0)^n dz = \int_C (z - z_0)^n dz = 0
\]
since these polynomials are entire. Thus,
\[
	\int_C S(z) dz = 0
\]
which implies the following corollary:

\textit{Corollary: the sum of a power series, $S(z)$, is analytic at each point interior to the circle of convergence.}

\textit{Example: Consider the function
\[
	f(z) = \begin{cases}
		(e^z - 1) / z,	& z \neq 0 \\
		1,				& z = 0
	\end{cases}
\]
This function has the Maclaurin series expansion
\[
	f(z) = \sum_{n=1}^\infty \frac{z^{n-1}}{n!}
	= 1 + \frac{z}{2!} + \frac{z^2}{3!} + \dots
\]
When $z = 0$ in this series, it evaluates to $1$, so it represents both of the cases defined in $f(z)$. Since this sum of polynomial terms is clearly entire, $f(z)$ must also be entire. The continuity of $f$ could also be evaluated by confirming that
\[
	\lim_{z \to 0} \frac{e^z - 1}{z} = f(0) = 1
\]}

Note that this corollary confirms that we have chosen the largest possible circle of convergence. We picked a circle centered at $z_0$ and intersecting the nearest non-analytic point $z_1$; if we chose a bigger circle, then it would contain $z_1$, incorrectly implying that $f$ is analytic at $z_1$.

\subsection{Differentiability}
Next, we can look at differentiability of power series:

\textit{Theorem: a power series can be differentiated term-by-term. That is,
\[
	S'(z) = \sum_{n=1}^\infty na_n (z - z_0)^{n-1}
\]}

To prove this, suppose that $C$ is, as above, a contour interior to the circle of convergence and $z$ is any point inside $C$. We can define the function
\[
	g(s) = \frac{1}{2\pi i} \frac{1}{(s - z)^2}
\]
which is continuous on $C$. Then, we can use Cauchy's integral formulas to write
\[
	\int_C g(s) S(s) ds 
	= \frac{1}{2\pi i} \int_C \frac{S(s)}{(s - z)^2} ds = S'(z) 
\]
However, we can alternatively write
\[
	\int_C g(s) S(s) ds = \sum_{n=0}^\infty a_n \int C g(s) (s - z_0)^n ds
\]
where each term of this sum is
\[
	\int_C g(s) (s - z_0)^n
	= \frac{1}{2\pi i} \int_C \frac{(s - z_0)^n}{(s - z)^2} ds
	= \frac{d}{dz} (z - z_0)^n
\]
so
\[
	S'(z) = \sum_{n=0}^\infty a_n \frac{d}{dz} (z - z_0)^n
\]

\textit{Example: we saw earlier that
\[
	\frac{1}{z} = \sum_{n=0}^\infty (-1)^n (z - 1)^n
\]
We can differentiate both sides to write
\[
	-\frac{1}{z^2} = \sum_{n=1}^\infty (-1)^n n(z - 1)^{n-1}
\]
or
\[
	\frac{1}{z^2} = \sum_{n=0}^\infty (-1)^n (n+1) (z - 1)^n
\]}



\end{document}